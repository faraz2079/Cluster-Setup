
#check the support for GPU
lspci | grep -i nvidia
nvidia-smi
nvidia-smi -L

# Add NVIDIA container toolkit repo
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list |
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#' |
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# Install toolkit
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# Configure Docker
sudo nvidia-ctk runtime configure --runtime=docker

# Restart Docker
sudo systemctl restart docker


sudo docker info | grep -i nvidia


#simple workload
sudo docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi


#or --runtime=crio
sudo nvidia-ctk runtime configure --runtime=containerd 

sudo systemctl restart containerd


#generate the file in the crio configuration and also restart afterwards
sudo nvidia-ctk runtime configure \
    --runtime=crio \
    --set-as-default \
    --config=/etc/crio/crio.conf.d/99-nvidia.conf

#command for restart
sudo systemctl restart crio


#the configuration file exists apparantely as .toml
sudo cat /etc/crio/conf.d/99-nvidia.toml

#checking
crio config | grep -A3 default_runtime

#generating the file and checking it
sudo mkdir -p /etc/crio/crio.conf.d/
sudo mv /etc/crio/conf.d/99-nvidia.toml /etc/crio/crio.conf.d/99-nvidia.toml
crio config | grep -A3 default_runtime

#deploy the nvidia kit for k8s
kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.17.1/deployments/static/nvidia-device-plugin.yml
